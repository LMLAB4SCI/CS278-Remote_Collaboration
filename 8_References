1. Alem L, Tecchia F, HuangW(2011) Remote tele-assistance system
for maintenance operators in mines. In: 11th Underground coal
operators’ conference. University of Wollongong
2. Baecker RM (1994) Readings in groupware and computersupported
cooperative work: assisting human–human collaboration,
1st edn. Morgan Kaufmann, San Francisco
3. Choudhary Z, Kim K, Schubert R, Bruder G, Welch GF (2020)
Virtual big heads: analysis of human perception and comfort of
head scales in social virtual reality. In: IEEE conference on virtual
reality and 3D user interfaces, pp 425–433
4. DeVincenzi A, Yao L, Ishii H, Raskar R (2011) Kinected conference:
augmenting video imaging with calibrated depth and audio.
In: Proceedings of the ACM 2011 conference on computer supported
cooperative work, pp 621-624
5. Dey A, Piumsomboon T, Lee Y, Billinghurst M (2017) Effects of
sharing physiological states of players in a collaborative virtual
reality gameplay. In: Proceedings of the 2017 CHI conference on
human factors in computing systems, pp 4045–4056
6. Erickson A, Norouzi N, Kim K, LaViola JJ, Bruder G, Welch GF
(2020) Effects of depth information on visual target identification
task performance in shared gaze environments. IEEE Trans Visu
Comput Graph 26(5):1934–1944
7. Erickson A, Norouzi N, Kim K, Schubert R, Jules J, LaViola JJ,
BruderG,WelchGF(2020) Sharing gaze rays for visual target identification
tasks in collaborative augmented reality. J Multimodal
User Interfaces. https://doi.org/10.1007/s12193-020-00330-2
8. Fakourfar O, Ta K, Tang R, Bateman S, Tang A (2016) Stabilized
annotations for mobile remote assistance. In: Proceedings of the
2016 CHI conference on human factors in computing systems, pp
1548–1560
9. Fussell SR, Setlock LD,Yang J,Ou J,Mauer E, Kramer ADI (2004)
Gestures over video streams to support remote collaboration on
physical tasks. Hum–Comput Interact 19(3):273–309
10. Gauglitz S, Nuernberger B, Turk M, Höllerer T (2014) Worldstabilized
annotations and virtual scene navigation for remote
collaboration. In: Proceedings of the 27th annual ACM symposium
on user interface software and technology, pp 449-459
11. Gupta K, Lee GA, Billinghurst M (2016) Do you see what i see?
The effect of gaze tracking on task space remote collaboration.
IEEE Trans Vis Comput Graph 22(11):2413–2422
12. Gutwin C, Greenberg S (1998) Design for individuals, design for
groups: tradeoffs between power and workspace awareness. In:
Proceedings of the ACM conference on computer supported cooperative
work, pp 207–216
13. Higuch K, Yonetani R, Sato Y (2016) Can eye help you? Effects
of visualizing eye fixations on remote collaboration scenarios for
physical tasks. In: Proceedings of the 2016 CHI conference on
human factors in computing systems, pp 5180–5190
14. Huang W, Alem L, Tecchia F, Duh HBL (2018) Augmented 3D
hands: a gesture-based mixed reality system for distributed collaboration.
J Multimodal User Interfaces 12(2):77–89
15. Huang W, Kim S, Billinghurst M, Alem L (2019) Sharing hand
gesture and sketch cues in remote collaboration. J Vis Commun
Image Represent 58:428–438
16. Irlitti A, Piumsomboon T, Jackson D, Thomas BH (2019) Conveying
spatial awareness cues in xR collaborations. IEEE Trans Visu
Comput Graph 25(11):3178–3189
17. Kasahara S, Rekimoto J (2014) JackIn: integrating first-person
view with out-of-body vision generation for human–human augmentation.
In: Proceedings of the 5th augmented human international
conference, pp 46:1–46:8
18. Kato H, Billinghurst M (1999) Marker tracking and HMD calibration
for a video-based augmented reality conferencing system.
In: Proceedings 2nd IEEE and ACM international workshop on
augmented reality (IWAR’99), pp 85–94
19. Kim K, Billinghurst M, Bruder G, Duh HBL, Welch GF (2018)
Revisiting trends in augmented reality research: a reviewof the 2nd
decade of ISMAR (2008–2017). IEEE Trans Vis Comput Graph
24(11):2947–2962
20. Kim K, Boelling L, Haesler S, Bailenson JN, Bruder G,Welch GF
(2018) Does a digital assistant need a body? The influence of visual
embodiment and social behavior on the perception of intelligent
virtual agents in AR. In: IEEE international symposium on mixed
and augmented reality, pp 105–114
21. KimK, deMeloC,NorouziN,BruderG,WelchG(2020) Reducing
task load with an embodied intelligent virtual assistant for improved
performance in collaborative decision making. In: Proceedings of
the IEEE conference on virtual reality and 3D user interfaces, pp
529–538
22. Kim K, Norouzi N, Losekamp T, Bruder G, Anderson M,Welch G
(2019) Effects of patient care assistant embodiment and computer
mediation on user experience. In: Proceedings of IEEE international
conference on artificial intelligence and virtual reality, pp
17–24
23. Kim K, Schubert R, Hochreiter J, Bruder G,Welch G (2019) Blowing
in the wind: increasing social presence with a virtual human via
environmental airflow interaction in mixed reality. Comput Graph
83:23–32
24. Kim S,Billinghurst M, LeeC, LeeG(2018) Using freeze frame and
visual notifications in an annotation drawing interface for remote
collaboration. KSII Trans Internet Inf Syst 12(12):6034–6056
25. Kim S, Billinghurst M, Lee G (2018) The effect of collaboration
styles and view independence on video-mediated remote collaboration.
Comput Support Cooper Work 27(3):569–607
26. Kim S,Lee G, Billinghurst M, HuangW(2020) The combination of
visual communication cues inmixed reality remote collaboration. J
Multimodal User Interfaces. https://doi.org/10.1007/s12193-020-
00335-x
27. Kim S, Lee G, Huang W, Kim H, Woo W, Billinghurst M (2019)
Evaluating the combination of visual communication cues for
HMD-based mixed reality remote collaboration. In: Proceedings
of the 2019 CHI conference on human factors in computing systems,
pp 1–13
28. Kim S, Lee G, Sakata N, Billinghurst M (2014) Improving copresence
with augmented visual communication cues for sharing
experience through video conference. In: Proceedings of the IEEE
international symposium on mixed and augmented reality, pp 83–
92
29. Kim S, Lee GA, Ha S, Sakata N, Billinghurst M (2015) Automatically
freezing live video for annotation during remote collaboration.
In: Proceedings of the 33rd annual ACMconference extended
abstracts on human factors in computing systems, pp 1669–1674
30. Kim S, Lee GA, Sakata N (2013) Comparing pointing and drawing
for remote collaboration. In: Proceedings of the IEEE international
symposium on mixed and augmented reality, pp 1–6
31. Kirk D, Stanton Fraser D (2006) Comparing remote gesture
technologies for supporting collaborative physical tasks. In: Proceedings
of the SIGCHI conference on human factors in computing
systems, pp 1191–1200
32. Kraut RE, Gergle D, Fussell SR (2002) The use of visual information
in shared visual spaces: informing the development of virtual
co-presence. In: Proceedings of the 2002ACMconference on computer
supported cooperative work, pp 31–40
33. Lecuyer A, Lotte F, Reilly R, Leeb R, Hirose M, Slater M (2008)
Brain–computer interfaces, virtual reality, and videogames. Computer
41(10):66–72
34. Lee G, Kang HY, Lee JM, Han JH (2020) A user study on viewsharing
techniques for one-to-many mixed reality collaborations.
In: Proceedings of the IEEE conference on virtual reality and 3D
user interfaces, pp 343–352
35. Lee G, Kim S, Lee Y, Dey A, Piumsomboon T, Norman M,
Billinghurst M (2017) Mutually shared gaze in augmented video
conference. In:Adjunct proceedings of the 2017 IEEE international
symposium on mixed and augmented reality-adjunct, pp 79–80
36. Lee G, Teo THL, Kim S, BillinghurstM(2018) A user study on mr
remote collaboration using live 360 video. In: Proceedings of the
IEEE international symposium for mixed and augmented reality,
pp 153–164
37. Lukosch S, Billinghurst M, Alem L, Kiyokawa K (2015) Collaboration
in augmented reality. Comput Support Cooper Work
24(6):515–525
38. Norouzi N, Erickson A, Kim K, Schubert R, Laviola Jr, JJ, Bruder
G, Welch GF (2019) Effects of shared gaze parameters on visual
target identification task performance in augmented reality. In:
Proceedings of ACM symposium on spatial user interaction, pp
12:1–12:11
39. Norouzi N, Kim K, Hochreiter J, Lee M, Daher S, Bruder G,Welch
G (2018) A systematic survey of 15 years of user studies published
in the intelligent virtual agents conference. In: Proceedings of the
ACMinternational conference on intelligent virtual agents, pp 17–
22
40. Norouzi N, Kim K, Lee M, Schubert R, Erickson A, Bailenson J,
Bruder G, Welch G (2019) walking your virtual dog: analysis of
awareness and proxemics with simulated support animals in augmented
reality. In: Proceedings of IEEE international symposium
on mixed and augmented reality, pp 253–264
41. Paro JA, Nazareli R, Gurjala A, Berger A, Lee GK (2015) Videobased
self-review. Ann Plast Surg 74:S71–S74
42. Piumsomboon T, Lee GA, Hart JD, Ens B, Lindeman RW, Thomas
BH, Billinghurst M (2018) Mini-Me: an adaptive avatar for mixed
reality remote collaboration. In: Proceedings of the 2018 CHI conference
on human factors in computing systems, pp 1–13
43. PiumsomboonT, Lee GA, Irlitti A, EnsB,Thomas BH,Billinghurst
M (2019) On the shoulder of the giant: a multi-scale mixed reality
collaboration with 360 video sharing and tangible interaction.
In: Proceedings of the 2019 CHI conference on human factors in
computing systems, pp 1–17
44. Teo T, Lawrence L, Lee GA, Billinghurst M, Adcock M (2019)
Mixed reality remote collaboration combining 360 video and 3D
reconstruction. In: Proceedings of the ACM CHI conference on
human factors in computing systems, vol 201. ACM Press, New
York, pp 1–14
45. Teo T, Norman M, Lee GA, Billinghurst M, Adcock M (2020)
Exploring interaction techniques for 360 panoramas inside a 3D
reconstructed scene for mixed reality remote collaboration. J
Multimodal User Interfaces. https://doi.org/10.1007/s12193-020-
00343-x
46. TomaselloM(2016) Precís of a natural history of human thinking.
J Soc Ontol 2(1):59–64
47. Yang J, Sasikumar P, Bai H, Barde A, Sörös G, Billinghurst M
(2020) The effects of spatial auditory and visual cues on mixed
reality remote collaboration. J Multimodal User Interfaces. https://
doi.org/10.1007/s12193-020-00331-1
48. Zhou J, Luo S, Chen F (2020) Effects of personality traits on user
trust in human-machine collaborations. J Multimodal User
